# paperReaderNote
用来记录自己研究僧阶段读取的论文，做一记录吧，在2019.05.01，有了这个记录的想法，但是一直却没有去做，最近正好没事，就拿出来一起好好开始自己的科研之路吧
# 前言
自己从2018.7.12来到这里，一直开始跟着师兄做一个关于文本的项目，目前该项目已经完结，自己也积累了一些工程上的开发技术，但是在论文上却一直没有一个研究生该有的样子。也学之前真的有想着划水过去毕业就好了，然后找一个工作，做一个卑微的人就好。后来遇见了林老师，让我深深的知道，如果只是这样的科研，那未来可期不过是自己骗自己的谎言。

所以，在研究生的过程中，去把它过得充实，然后不断的去努力，未来才可以掌握在自己手里，就想打王者一样，与其说队友坑，不如把输出掌握在自己手里，宁可钻石局5法师的重开，也不远将自己最擅长的输出，放在队友手里，最后要么carry全场，要么被喷。科研也一样，我不想让自己的命运，安安稳稳的划在别人的手里，我会将输出握在我自己的手里。

所以，加油！

# 论文
## 1. A Biterm Topic Model for Short Texts(BTM).pdf
   - 内容概要：这是针对短文本主题模型的论文，属于 主题模型  族的论文。主要描述了短文本上的主题分析。 
   - 创新点：  
       1. LDA主要是用单个词，作为基本的处理单元，但是BTM这里是使用了次对的形式，来作为其操作的基本单元，及时了该词对只有一个主题，然后服从了狄利克雷的先验假设分布，其余过程和LDA类似 ,在推断过程依然采用了Gibbs采样的推断过程。
       2. 通过设置窗口的大小，将窗口内的词对两两组合构成词对，解决了短文上数据文档级别的单词贡献的的数据稀疏想问题  
   - 对比实验
       1. 标准LDA  
       2. Mixtrue of unigrams 这个也是假设了一个或者词只有一个topic，而非多个topic
   - 指标
       1. 主题质量通过主题连贯性来进行检验，在短文本和正规文本上做了实验
       2. 通过其他的手段来定量的分析，聚类通过 纯度Purity，互信息NMI(Normalized Mutual Information), ARI(Adjust Rand Index)三个指标判断主题模型对下游任务的影响
       3. 质量分析，通过计算LDA和BTM 得到的主题词的余弦相似度来判定其差异
## 2. Automatic Labeling of Topic Models Using Text Summaries.pdf
   - 作者简介：万小军，北京大学自然语言处理研究所负责人，主要是文本摘要
   - 内容概要：本文首次提出了给主题模型跑出来的抽象的topic，进行主题实际意义的命名。以前有人尝试过用 单词，短语，和图像来进行直观的主题的主题描述，还有抽取抽取句子作为主题的描述。本文定义了怎样的主题label是更好的，只要是 主题label和主题词的高相关性，高概括性，不同topic之间的高区分性。本文提出了基于子模优化的算法进行候选句子的筛选。
   - 创新点： 
       1. 首次提出了用文本摘要进行主题打标签
       2. 基于子模优化的文本摘要生成算法
   - 对比实验
       1. MEAD：使用启发的策略进行发现和第一个句子相似的每个句子分数
       2. LEXRank：就是句子的pageRank 算法
       3. REL：子模函数最大化
      - 标签比较：词标签，短语标签，句子标签
   - 指标：
       1. 候选句子的选择：主要靠KL散度进行来进行选择
       2. 主题摘要：主要靠增益递减的子模函数来进行选择。
       3. 定义了相关性函数 KL散度，余弦相似
       4. 定义了概括性函数
       5. 定义了区别性函数
       6. 定义了贪心的选择算法，根据2,3,4的定义相加构成的子模函数
      ###### 总结
      之前我们有尝试去解决这个topic lable的问题，尝试的办法，采用了单词的短语的形式，做法上可能相对简单，通过人工命名部分抽象名词，通过词林扩展的形式扩充好单词，采用余弦相似度和jacard相似度来进行topic的命名，这样实现的是一个半自动话的主题命名方式。今天看到万老师的这一篇文章，可以说是有了很大的了解。
## 3. generative-adversarial-nets.pdf
- 内容概要：本文首次提出了生成对抗的神经网络，也就是大名鼎鼎的GAN，当时主要用于图像的生成，论文介绍的GAN主要有两个部分组成，一个是生成神经网络，一个是判别神经网络。生成网络用与捕获数据的分布，判别神经网络，主要判断采样训练数据的真实的可能性，所以生成过程是以最大化的生成数据分布的过程，判别过程是一个最小化判别误差的过程，最后构成了最大最小化的游戏。两个过程都有多层感知机构成，论文对比说明了该框架和目前存在的一些两段的神经网络的区别。
- 创新点：  
   1. 首次提出了生成对抗神经网络
   2. 克服了其他神经网络的随机性的问题，提出了该网络满足两个玩家的各自的策略均等的。
- 总结：  
   因为目前本人水平有限，该论文写的简单，但是很深奥，只能了解个大概的思想，不能够体会到其具体的精妙之处，以后还需要多积累一些之后再来读，会有不一样的体会。
## 4. Short_and_Sparse_Text_Topic_Modeling_via_Self-Aggregation.pdf
- 内容概要：本文主要描述了一个解决短文本的数据的数据稀疏性问题的更加广义的解决办法，提出了通过短文本在主题推断时的自聚合得到的一个广义的解决方案。自聚合是通过广义的主题的亲和度而不是其他论文的启发式的策略，使得该模型更加适应多样性的短文本。实验在两个真实实验数据集上进行实验。
- 创新点：  
    1. 解决了数据的稀疏性问题：通过更多有用的单词共现信息被有效的短文本版相似的主题聚类所创建，同时假设了每个短文本一定是采样来自一篇的伪长文本  
    2. 提出了两个新的评估准则。一个是互信息的评估，一个是最大化alignment的摘要主题，也就是纯度作为一个新的评估准则。
- 模型：
    主要分为两段的生成过程，第一段的假设就是标准的LDA假设，去生成一个标准的文档集合。第二段就是利用前一段生成的长文本来生成短文本，也就是每个短文本是一个长文本的多项式采样过程  
    推断过程还是通过Gibbs采样的过程。
- 数据集：
   1. NIPS：NIPS COFFERCE PAPER
   2. Yahoo！Answers. http://answers.yahoo.com/
- 总结：本文通过长文本来解决短文本的稀疏性问题的解决，提出的纯度的评估准则，后来作为评估主题的一个重要的手段。


最近的自己真的是浪得很，一方面是一位懒，一方卖弄是因为总是被各种事打扰，没有细心去读了论文，真是罪过啊！！！
## 5. Recent_Advances_in_Document_Summarization.pdf  
- 内容描述：这是一篇关于最近几年先进的文本摘要或者文本总结的综述性论文，完整翻译见[https://blog.csdn.net/jinhao_2008/article/details/78695508]
   + 什么是好的摘要或者总结？ 覆盖单文本或多文本（每个聚类）的重要信息，并且不重复，语法上连贯。
   + 目前的方法：主要来提高概念覆盖，信息多样，内容相关性。同时也在尝试句子压缩和生成。
   + 文本摘要分类：单一文档，和多文档（或者说是单一文本的聚类，如lda的结果）
   + 区别：
       1. 抽取总结：从原生的文本中抽取出一些重要的句子凭借起来作为总结
       2. 摘要总结：用不同的单词构成的句子来描述文档内容的信息，而不是抽取原句。这也是生成摘要。
- 目前方法介绍：
   + 经典的方法：句子水平的操作。如句子压缩，句子重组。大致有如下三个要素：
     1. 句子分数：每个句子计算一个分数，预留最重要的信息。
     + 早期的无监督的方式，主要是通过频率和中心化进行来计算分数。 有计算单词的概率，
     + 发展到有基于图摘要的框架，如pagerank衍生出来的TextRank等算法。
     + 在中心化（高于一定的阈值的tfidf的单词构成）的算法中，句子分数是定义为基于和中心句的不同特征包含余弦相似度的之和。  
     + 概率主主题模型是基于单词共现的信息，例如hLDA算法，所有这些的共同点都是从文档中抽出重复信息最高的句子。在噪声很大的文本中就抽不到了。  
     + 目前一些机器学习的算法应用到该领域。给定一个句子和其对应分数lable进行训练回归模型，然后直接预测句子得分。或者是一些排名的算法来给句子排名。后来隐马尔科夫，条件随机场和SVM都会用来抽取摘要，但是这种方法严重的依赖与训练集的大小。查询类的摘要主要计算查询的句子和每个句子之间的相似度。
     2. 句子筛选:选取最能代表文章中心的句子作为代表。
     + 根据第一步句子得到的分数，最直接的方式是选取分数高的句子，但这个现象在多文档摘要中会使得重复的信息严重。
     + 典型的句子选择算法是 最大边缘相关（maximum marginal relevance(MMR)）算法，详细的描述见[https://blog.csdn.net/eliza1130/article/details/24033161] 
     + 概率的办法就是在概率分布和输入的单词评估之间 最小化KL(Kullback-Leibler)散度，也为相对熵。详见 [https://baike.baidu.com/item/%E7%9B%B8%E5%AF%B9%E7%86%B5/4233536?fr=aladdin]，  
     + 最广泛的还是整合线性规划（ILP），目标在受限的情况下最大化覆盖率。
     3. 句子标准化：对选出的句子进行修改和压缩，形成总结性的句子。根据第二部选择出的句子可能包含重复和不必要的信息。  
     有两种方法解决这类问题： 流水线是抽取，基于规则的压缩。
     在单文档的摘要中保证句子在原来文档中的顺序；在多文档的摘要中则要重排顺序。经典的重排句子的策略是句子权重图或者是基于时间戳和位置的时间排序算法。
  + 评估策略：（好的摘要易读和有高概括性）
     - ROUGE(Recall-oriented Understudy for Gisty Evalustion)：ROUGE基于摘要中n元词(n-gram)的共现信息来评价摘要，是一种面向n元词召回率的评价方法。基本思想为由多个专家分别生成人工摘要，构成标准摘要集，将系统生成的自动摘要与人工生成的标准摘要相对比，通过统计二者之间重叠的基本单元(n元语法、词序列和词对)的数目，来评价摘要的质量。通过与专家人工摘要的对比，提高评价系统的稳定性和健壮性.详细见[https://blog.csdn.net/mch2869253130/article/details/89810974].
     - 当然还有其他的自动文摘的评测办法，论文一提而过。
  + 目前方法介绍  
     文本摘要要求信息覆盖，连贯性，不冗余，和简洁性。基于查询的文本摘要还是计算查询和语句的相似度和overlap度。
     - 基于ILP的概念提高：基于频率的改进
     - 子模函数最大化的多样性改进：
     - 句子连贯性的改进：连贯性分数可通过话语图(dicourse graph)。
